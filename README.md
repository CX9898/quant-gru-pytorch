# Quant-GRU-PyTorch

ä¸€ä¸ªé«˜æ€§èƒ½çš„é‡åŒ– GRUï¼ˆé—¨æ§å¾ªç¯å•å…ƒï¼‰å®ç°ï¼ŒåŸºäº CUDA å’Œ PyTorchï¼Œæ”¯æŒè®­ç»ƒå’Œæ¨ç†çš„é‡åŒ–æ„ŸçŸ¥è®¡ç®—ã€‚

## ğŸ“‹ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªæ”¯æŒé‡åŒ–çš„ GRU ç¥ç»ç½‘ç»œæ¨¡å—ï¼Œæ ¸å¿ƒä½¿ç”¨ CUDA ç¼–å†™ä»¥å®ç°é«˜æ€§èƒ½è®¡ç®—ï¼Œå¹¶é€šè¿‡ PyBind11 æä¾› PyTorch æ¥å£ã€‚é¡¹ç›®æ”¯æŒï¼š

- **æµ®ç‚¹å’Œé‡åŒ–ä¸¤ç§æ¨¡å¼**ï¼šå¯åœ¨è®­ç»ƒå’Œæ¨ç†æ—¶è‡ªç”±åˆ‡æ¢
- **çµæ´»çš„é‡åŒ–é…ç½®**ï¼šæ”¯æŒ 8/16/32 ä½é‡åŒ–ï¼Œå¯é…ç½®å¯¹ç§°/éå¯¹ç§°é‡åŒ–
- **ä¸¤ç§æ ¡å‡†æ–¹æ³•**ï¼šMinMaxï¼ˆå¿«é€Ÿï¼‰å’Œ Histogramï¼ˆAIMET é£æ ¼ï¼Œé«˜ç²¾åº¦ï¼‰
- **åŒå‘ GRU**ï¼šå®Œæ•´æ”¯æŒ bidirectional æ¨¡å¼
- **ä¸ PyTorch å…¼å®¹**ï¼šæ¥å£ä¸ `nn.GRU` ä¸€è‡´ï¼Œå¯æ— ç¼æ›¿æ¢

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
quant-gru-pytorch/
â”œâ”€â”€ include/                    # C++/CUDA å¤´æ–‡ä»¶
â”‚   â”œâ”€â”€ gru.h                   # æµ®ç‚¹ GRU å‰å‘/åå‘ä¼ æ’­ç±»
â”‚   â”œâ”€â”€ gru_quant.h             # é‡åŒ– GRU å‰å‘ä¼ æ’­ç±»
â”‚   â”œâ”€â”€ gru_interface.hpp       # ç»Ÿä¸€æ¥å£å±‚ï¼ˆæ ¡å‡†ã€é‡åŒ–ã€å‰å‘ä¼ æ’­ï¼‰
â”‚   â”œâ”€â”€ quantize_bitwidth_config.hpp  # é‡åŒ–ä½å®½é…ç½®
â”‚   â”œâ”€â”€ quantize_ops.cuh        # é‡åŒ–æ“ä½œ CUDA å†…æ ¸
â”‚   â”œâ”€â”€ histogram_collector.hpp # ç›´æ–¹å›¾æ”¶é›†å™¨ï¼ˆAIMET é£æ ¼æ ¡å‡†ï¼‰
â”‚   â”œâ”€â”€ pot_sqnr_calibrator.hpp # SQNR æ ¡å‡†å™¨
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/                        # C++/CUDA æºæ–‡ä»¶
â”‚   â”œâ”€â”€ gru_forward_gpu.cu      # æµ®ç‚¹å‰å‘ä¼ æ’­ GPU å®ç°
â”‚   â”œâ”€â”€ gru_forward_gpu_quant.cu # é‡åŒ–å‰å‘ä¼ æ’­ GPU å®ç°
â”‚   â”œâ”€â”€ gru_backward_gpu.cu     # åå‘ä¼ æ’­ GPU å®ç°
â”‚   â”œâ”€â”€ gru_interface.cpp       # æ¥å£å®ç°
â”‚   â””â”€â”€ quantize_ops.cu         # é‡åŒ–æ“ä½œå®ç°
â”œâ”€â”€ pytorch/                    # PyTorch ç»‘å®šå’Œ Python æ¥å£
â”‚   â”œâ”€â”€ custom_gru.py           # è‡ªå®šä¹‰ GRU ç±»ï¼ˆæ”¯æŒé‡åŒ–ï¼‰
â”‚   â”œâ”€â”€ setup.py                # Python æ‰©å±•ç¼–è¯‘é…ç½®
â”‚   â”œâ”€â”€ lib/                    # ç¼–è¯‘ç”Ÿæˆçš„åº“æ–‡ä»¶
â”‚   â”œâ”€â”€ config/                 # é…ç½®æ–‡ä»¶
â”‚   â”‚   â””â”€â”€ gru_quant_bitwidth_config.json  # é‡åŒ–ä½å®½é…ç½®
â”‚   â””â”€â”€ test_*.py               # æµ‹è¯•è„šæœ¬
â”œâ”€â”€ example/                    # C++ ä½¿ç”¨ç¤ºä¾‹
â”‚   â””â”€â”€ gru.cc                  # æµ®ç‚¹/é‡åŒ– GRU å¯¹æ¯”ç¤ºä¾‹
â”œâ”€â”€ CMakeLists.txt              # CMake æ„å»ºé…ç½®
â”œâ”€â”€ gru_train.py                # PyTorch è®­ç»ƒç¤ºä¾‹ï¼ˆè¯­éŸ³è¯†åˆ«ï¼‰
â”œâ”€â”€ Dockerfile                  # Docker æ„å»ºæ–‡ä»¶
â””â”€â”€ docker-compose.yml          # Docker Compose é…ç½®
```

## ğŸ”§ ç¯å¢ƒè¦æ±‚

- **CUDA Toolkit** >= 11.0
- **cuBLAS**
- **C++17** ç¼–è¯‘å™¨
- **CMake** >= 3.18
- **Python** >= 3.8
- **PyTorch** >= 1.10ï¼ˆæ”¯æŒ CUDAï¼‰
- **OpenMP**

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¼–è¯‘ C++ åº“

```bash
# åˆ›å»ºæ„å»ºç›®å½•
mkdir build && cd build

# é…ç½® CMake
cmake ..

# ç¼–è¯‘
make -j$(nproc)
```

ç¼–è¯‘å®Œæˆåä¼šç”Ÿæˆï¼š
- `pytorch/lib/libgru_quant_static.a` - é™æ€åº“
- `pytorch/lib/libgru_quant_shared.so` - åŠ¨æ€åº“
- `gru_example` - C++ ç¤ºä¾‹ç¨‹åº

### 2. ç¼–è¯‘ Python æ‰©å±•

```bash
cd pytorch

# å®‰è£… Python æ‰©å±•
pip install -e .
```

### 3. ä½¿ç”¨ç¤ºä¾‹

#### Python ä½¿ç”¨ï¼ˆéé‡åŒ–æ¨¡å¼ï¼‰

```python
from pytorch.custom_gru import CustomGRU
import torch

# åˆ›å»ºæ¨¡å‹ï¼ˆä¸ nn.GRU æ¥å£ä¸€è‡´ï¼‰
gru = CustomGRU(
    input_size=64,
    hidden_size=128,
    batch_first=True,
    bidirectional=False
).cuda()

# å‰å‘ä¼ æ’­
input_data = torch.randn(32, 50, 64).cuda()  # [batch, seq_len, input_size]
output, h_n = gru(input_data)
# output: [32, 50, 128], h_n: [1, 32, 128]
```

#### Python ä½¿ç”¨ï¼ˆé‡åŒ–æ¨¡å¼ï¼‰

```python
from pytorch.custom_gru import CustomGRU
import torch

# 1. åˆ›å»ºæ¨¡å‹
gru = CustomGRU(
    input_size=64,
    hidden_size=128,
    batch_first=True
).cuda()

# 2. (å¯é€‰) åŠ è½½è‡ªå®šä¹‰ä½å®½é…ç½®
gru.load_bitwidth_config("config/gru_quant_bitwidth_config.json", verbose=True)

# 3. ä½¿ç”¨æ ¡å‡†æ•°æ®è¿›è¡Œé‡åŒ–æ ¡å‡†
for batch in calibration_loader:
    gru.calibrate(batch.cuda())

# 4. å®Œæˆæ ¡å‡†ï¼Œè®¡ç®—é‡åŒ–å‚æ•°
gru.finalize_calibration(verbose=True)

# 5. å¼€å¯é‡åŒ–æ¨¡å¼è¿›è¡Œæ¨ç†
gru.use_quantization = True
output, h_n = gru(input_data)
```

#### è®¾ç½®æ ¡å‡†æ–¹æ³•

```python
# MinMax æ ¡å‡†ï¼ˆé»˜è®¤ï¼Œé€Ÿåº¦å¿«ï¼‰
gru.calibration_method = 'minmax'

# AIMET é£æ ¼ç›´æ–¹å›¾æ ¡å‡†ï¼ˆç²¾åº¦é«˜ï¼Œæ¨èï¼‰
gru.calibration_method = 'histogram'
```

## âš™ï¸ é‡åŒ–é…ç½®

### é‡åŒ–ä½å®½é…ç½®æ–‡ä»¶æ ¼å¼

é…ç½®æ–‡ä»¶ `pytorch/config/gru_quant_bitwidth_config.json`ï¼š

```json
{
  "GRU_config": {
    "default_config": {
      "disable_quantization": false
    },
    "operator_config": {
      "input.x": { "bitwidth": 8, "is_symmetric": false },
      "input.h": { "bitwidth": 8, "is_symmetric": false },
      "weight.W": { "bitwidth": 8, "is_symmetric": true },
      "weight.R": { "bitwidth": 8, "is_symmetric": true },
      "gate.z_out": { "bitwidth": 8, "is_symmetric": false },
      ...
    }
  }
}
```

### å¯é…ç½®çš„ç®—å­

| ç±»åˆ« | ç®—å­å | è¯´æ˜ |
|------|--------|------|
| è¾“å…¥ | `input.x`, `input.h` | è¾“å…¥åºåˆ—å’Œéšè—çŠ¶æ€ |
| æƒé‡ | `weight.W`, `weight.R`, `weight.bx`, `weight.br` | æƒé‡çŸ©é˜µå’Œåç½® |
| çŸ©é˜µä¹˜æ³• | `matmul.Wx`, `matmul.Rh` | çŸ©é˜µä¹˜æ³•ä¸­é—´ç»“æœ |
| é—¨æ§ | `gate.z_pre/out`, `gate.r_pre/out`, `gate.g_pre/out` | é—¨æ§æ¿€æ´»å‰å |
| è¿ç®— | `op.Rh_add_br`, `op.rRh`, `op.old_contrib`, `op.new_contrib` | ä¸­é—´è¿ç®— |

### å¿«é€Ÿè®¾ç½®æ‰€æœ‰ä½å®½

```python
# è®¾ç½®æ‰€æœ‰ç®—å­ä½¿ç”¨ 8bit å¯¹ç§°é‡åŒ–
gru.set_all_bitwidth(8, is_symmetric=True)

# è®¾ç½®æ‰€æœ‰ç®—å­ä½¿ç”¨ 16bit éå¯¹ç§°é‡åŒ–
gru.set_all_bitwidth(16, is_symmetric=False)
```

## ğŸ“ GRU å…¬å¼

æœ¬é¡¹ç›®å®ç°çš„ GRU éµå¾ªä»¥ä¸‹è®¡ç®—å…¬å¼ï¼š

```
z_t = Ïƒ(W_z Â· x_t + R_z Â· h_{t-1} + b_z)        # æ›´æ–°é—¨
r_t = Ïƒ(W_r Â· x_t + R_r Â· h_{t-1} + b_r)        # é‡ç½®é—¨
g_t = tanh(W_g Â· x_t + r_t âŠ™ (R_g Â· h_{t-1}) + b_g)  # å€™é€‰éšè—çŠ¶æ€
h_t = z_t âŠ™ h_{t-1} + (1 - z_t) âŠ™ g_t          # æ–°éšè—çŠ¶æ€
```

å…¶ä¸­ï¼š
- `Ïƒ` è¡¨ç¤º Sigmoid æ¿€æ´»å‡½æ•°
- `âŠ™` è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•

## ğŸ§ª è¿è¡Œæµ‹è¯•

### C++ æµ‹è¯•

```bash
./build/gru_example
```

### Python æµ‹è¯•

```bash
cd pytorch
python test_custom_gru_quantization.py
```

## ğŸ”¬ æ ¡å‡†æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|----------|
| **MinMax** | é€Ÿåº¦å¿«ï¼Œå®ç°ç®€å• | å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ | å¿«é€ŸåŸå‹éªŒè¯ |
| **Histogram (AIMET)** | ç²¾åº¦é«˜ï¼ŒSQNR ä¼˜åŒ– | è®¡ç®—å¼€é”€ç¨å¤§ | ç”Ÿäº§éƒ¨ç½² |

## ğŸ“Š æ€§èƒ½

é‡åŒ–åçš„ GRU ç›¸æ¯”æµ®ç‚¹ç‰ˆæœ¬ï¼š
- **å†…å­˜å ç”¨**ï¼šå‡å°‘çº¦ 75%ï¼ˆ8-bit é‡åŒ–ï¼‰
- **è®¡ç®—é€Ÿåº¦**ï¼šæå‡çº¦ 2-4xï¼ˆå–å†³äºç¡¬ä»¶ï¼‰
- **ç²¾åº¦æŸå¤±**ï¼š< 1%ï¼ˆä½¿ç”¨ Histogram æ ¡å‡†ï¼‰

## ğŸ³ Docker ä½¿ç”¨

```bash
# æ„å»ºé•œåƒ
docker-compose build

# è¿è¡Œå®¹å™¨
docker-compose up -d

# è¿›å…¥å®¹å™¨
docker-compose exec quant-gru bash
```

## ğŸ“ API å‚è€ƒ

### CustomGRU ç±»

```python
class CustomGRU(nn.Module):
    def __init__(
        self,
        input_size: int,           # è¾“å…¥ç‰¹å¾ç»´åº¦
        hidden_size: int,          # éšè—çŠ¶æ€ç»´åº¦
        num_layers: int = 1,       # å±‚æ•°ï¼ˆç›®å‰ä»…æ”¯æŒ 1ï¼‰
        bias: bool = True,         # æ˜¯å¦ä½¿ç”¨åç½®
        batch_first: bool = False, # è¾“å…¥æ ¼å¼
        bidirectional: bool = False,  # æ˜¯å¦åŒå‘
        use_quantization: bool = False  # æ˜¯å¦å¯ç”¨é‡åŒ–
    )
```

### ä¸»è¦æ–¹æ³•

| æ–¹æ³• | è¯´æ˜ |
|------|------|
| `forward(input, hx=None)` | å‰å‘ä¼ æ’­ |
| `calibrate(data)` | ç´¯ç§¯æ ¡å‡†æ•°æ® |
| `finalize_calibration(verbose=False)` | å®Œæˆæ ¡å‡†ï¼Œè®¡ç®—é‡åŒ–å‚æ•° |
| `reset_calibration()` | é‡ç½®æ ¡å‡†çŠ¶æ€ |
| `load_bitwidth_config(path, verbose=False)` | åŠ è½½ä½å®½é…ç½® |
| `set_all_bitwidth(bitwidth, is_symmetric=True)` | è®¾ç½®ç»Ÿä¸€ä½å®½ |
| `is_calibrated()` | æ£€æŸ¥æ˜¯å¦å·²æ ¡å‡† |
| `print_quant_params()` | æ‰“å°é‡åŒ–å‚æ•° |
| `print_quant_ranges()` | æ‰“å°é‡åŒ–èŒƒå›´ |

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

## ğŸ“š å‚è€ƒ

- [AIMET (AI Model Efficiency Toolkit)](https://github.com/quic/aimet)
- [Haste: Fast RNN Library](https://github.com/lmnt-com/haste)
- [PyTorch Quantization](https://pytorch.org/docs/stable/quantization.html)

