# 分段线性量化原理详解

## 一、核心思想

### 1.1 问题背景

在量化神经网络中，我们需要在**整数域**计算激活函数（如 Sigmoid、Tanh），而不能使用浮点运算。

**传统方法**：查表法（LUT）
- 优点：简单直接
- 缺点：内存占用大（256个值），精度有限

**分段线性拟合方法**：
- 将激活函数分成多段（如32段）
- 每段用线性函数 `y = bx + c` 近似
- 在整数域计算，无需浮点运算

### 1.2 数学原理

**浮点域**：Sigmoid 函数
```
y = sigmoid(x) = 1 / (1 + exp(-x))
```

**分段线性近似**：
```
y ≈ b_i * x + c_i  (对于第 i 段)
```

其中 `b_i` 和 `c_i` 通过最小二乘法拟合得到。

## 二、量化转换原理

### 2.1 量化关系

所有量化都使用 **2的幂次方缩放因子**：

```
scale = 2^(-shift_bits)
```

**量化公式**：
```
q = round(x / scale) + zp
```

**反量化公式**：
```
x = scale * (q - zp)
```

### 2.2 输入量化

输入 `x` 被量化为 `q_x`：
```
q_x = round(x / scale_x) + zp_x
```

其中：
- `scale_x = 2^(-shift_bits_x)`
- `zp_x` 是 zero-point（用于处理负数）

**示例**：
- `x = 0.1`
- `scale_x = 2^-12 = 0.000244140625`
- `zp_x = 24576`
- `q_x = round(0.1 / 2^-12) + 24576 = 24986`

### 2.3 系数量化

线性拟合系数 `b` 和 `c` 也需要量化：

**系数 b（对称量化，zp=0）**：
```
q_b = round(b / scale_b)
```

**系数 c（需要烘焙 zero-point）**：
```
c_adjusted = c + zp_y * scale_y
q_c = round(c_adjusted / scale_c)
```

## 三、整数域计算原理

### 3.1 基本思路

在浮点域，我们计算：
```
y = b * x + c
```

在量化域，我们需要计算：
```
q_y = f(q_x, q_b, q_c, ...)
```

### 3.2 数学推导

**步骤1：反量化输入**
```
x = scale_x * (q_x - zp_x)
```

**步骤2：浮点计算**
```
y = b * x + c
  = b * scale_x * (q_x - zp_x) + c
  = b * scale_x * q_x - b * scale_x * zp_x + c
```

**步骤3：量化输出**
```
q_y = round(y / scale_y) + zp_y
    = round((b * scale_x * q_x - b * scale_x * zp_x + c) / scale_y) + zp_y
```

**步骤4：分离常数项**
```
q_y = round(b * scale_x / scale_y * q_x) 
    - round(b * scale_x / scale_y * zp_x)
    + round(c / scale_y)
    + zp_y
```

**步骤5：引入去零点**
```
x_offset = q_x - zp_x

q_y = round(b * scale_x / scale_y * (x_offset + zp_x))
    - round(b * scale_x / scale_y * zp_x)
    + round(c / scale_y)
    + zp_y

    = round(b * scale_x / scale_y * x_offset)
    + round(c / scale_y) + zp_y
```

### 3.3 使用移位操作

由于所有 scale 都是 2 的幂次方：
```
scale_x = 2^(-shift_bits_x)
scale_y = 2^(-shift_bits_y)
scale_b = 2^(-shift_bits_b)
```

所以：
```
b * scale_x / scale_y = q_b * scale_b * scale_x / scale_y
                      = q_b * 2^(-shift_bits_b) * 2^(-shift_bits_x) / 2^(-shift_bits_y)
                      = q_b * 2^(-(shift_bits_b + shift_bits_x - shift_bits_y))
```

**定义**：
```
n_BX_total = shift_bits_b + shift_bits_x - shift_bits_y
```

则：
```
b * scale_x / scale_y * x_offset = q_b * x_offset * 2^(-n_BX_total)
```

在整数域，这相当于：
```
term_bx = (q_b * x_offset) >> n_BX_total
```

### 3.4 常数项处理

对于 `c` 项：
```
c / scale_y = (q_c * scale_c) / scale_y
            = q_c * 2^(-shift_bits_c) / 2^(-shift_bits_y)
            = q_c * 2^(-(shift_bits_c - shift_bits_y))
```

**定义**：
```
n_yc = shift_bits_c - shift_bits_y
```

加上 zero-point 烘焙：
```
term_c = (q_c >> n_yc) + zp_y  (在量化域)
```

但为了简化，我们在拟合阶段就烘焙 zero-point：
```
c_adjusted = c + zp_y * scale_y
q_c = round(c_adjusted / scale_c)
term_c_precomputed = q_c >> n_yc  (已包含 zero-point 效果)
```

## 四、优化原理

### 4.1 移位融合优化

**原始流程**（两步移位）：
```
bx_32 = q_b * x_offset
q_bx = bx_32 >> n_bx        // 第一步：对齐到 bx 域
term_bx = q_bx >> n_yb      // 第二步：对齐到输出域
```

**优化后**（一步移位）：
```
bx_32 = q_b * x_offset
term_bx = bx_32 >> n_BX_total  // 融合移位
```

其中：
```
n_BX_total = n_bx + n_yb
           = (shift_bits_b + shift_bits_x - shift_bits_bx) 
           + (shift_bits_bx - shift_bits_y)
           = shift_bits_b + shift_bits_x - shift_bits_y
```

**优势**：
- 减少一次移位操作
- 减少中间变量存储

### 4.2 预计算优化

**原始流程**（运行时计算）：
```
term_c = q_c >> n_yc  (运行时计算)
```

**优化后**（预计算）：
```
term_c_precomputed = q_c >> n_yc  (拟合阶段计算，存储在 LUT 中)
```

**优势**：
- 运行时直接查表，无需计算
- 减少运行时开销

## 五、完整计算流程

### 5.1 数学公式

**最终公式**（优化后）：
```
q_y = (q_b · (q_x - z_x)) >> n_BX_total + term_c_precomputed
```

### 5.2 计算步骤

**步骤1：段查找**
```
segment_id = find_segment(q_x, thresholds)
```
- 比较 `q_x` 与阈值数组，确定属于哪个段

**步骤2：参数读取**
```
从 LUT 读取：
- q_b (INT16)
- n_BX_total (INT8)
- term_c_precomputed (INT32)
```

**步骤3：去零点**
```
x_offset = q_x - zp_x  (INT16)
```
- 将量化值转换为相对于 zero-point 的偏移

**步骤4：乘法 + 移位融合**
```
bx_32 = q_b * x_offset  (INT32)
term_bx = bx_32 >> n_BX_total  (或左移，如果 n_BX_total < 0)
```
- 计算 `b * x` 项
- 使用融合移位直接对齐到输出域

**步骤5：相加**
```
y_32 = term_bx + term_c_precomputed  (INT32)
```
- 加上常数项（已包含 zero-point）

**步骤6：饱和**
```
q_y = clip(y_32, 0, 65535)  (UINT16)
```
- 确保结果在量化范围内

## 六、示例计算

### 6.1 输入参数

- `x = 0.1` (浮点)
- `scale_x = 2^-12`
- `zp_x = 24576`
- `scale_y = 2^-16`
- `zp_y = -1`

### 6.2 计算过程

**步骤1：输入量化**
```
q_x = round(0.1 / 2^-12) + 24576
    = round(409.6) + 24576
    = 24986
```

**步骤2：去零点**
```
x_offset = 24986 - 24576 = 410
```

**步骤3：段查找**
假设找到 Segment 8，参数：
- `q_b = 32619`
- `n_BX_total = 13` (假设值)
- `term_c_precomputed = 32770`

**步骤4：乘法 + 移位**
```
bx_32 = 32619 * 410 = 13373790
term_bx = 13373790 >> 13 = 1632
```

**步骤5：相加**
```
y_32 = 1632 + 32770 = 34402
```

**步骤6：饱和**
```
q_y = clip(34402, 0, 65535) = 34402
```

**步骤7：反量化验证**
```
y = 2^-16 * (34402 - (-1)) = 0.5249
真实值: sigmoid(0.1) = 0.5250
误差: 0.0001 ✓
```

## 七、为什么这样设计？

### 7.1 为什么用 2 的幂次方？

- **硬件友好**：移位操作比除法快得多
- **精度可控**：通过调整 `shift_bits` 控制精度
- **实现简单**：只需移位，无需浮点运算

### 7.2 为什么分段？

- **精度提升**：线性函数在局部区域更准确
- **内存效率**：32段只需存储 32 组参数，比 256 值 LUT 更省内存
- **计算简单**：只需乘法和加法

### 7.3 为什么融合移位？

- **性能优化**：减少一次移位操作
- **代码简化**：减少中间变量
- **精度保持**：数学等价，不影响精度

### 7.4 为什么预计算 term_c？

- **性能优化**：运行时直接查表，无需计算
- **精度保证**：在拟合阶段精确计算，避免运行时误差累积

## 八、关键设计点

### 8.1 数据类型选择

- **输入/输出**：UINT16（无符号，通过 zero-point 处理负数）
- **系数 b**：INT16（有符号，对称量化）
- **中间结果**：INT32（避免溢出）
- **常数项**：INT32（预计算后存储）

### 8.2 Zero-point 处理

- **输入**：`x_offset = q_x - zp_x` 将量化值转换为偏移
- **输出**：在拟合阶段烘焙到 `c` 中，运行时无需额外处理

### 8.3 溢出保护

- 乘法结果用 INT32 存储
- 饱和操作确保最终结果在 UINT16 范围内

## 九、总结

分段线性量化的核心原理：

1. **分段近似**：将非线性函数分成多段，每段用线性函数近似
2. **整数计算**：所有计算都在整数域进行，使用移位代替除法
3. **优化策略**：移位融合和预计算减少运行时开销
4. **精度保证**：通过合理的分段和量化参数选择，保证计算精度

这种方法在保持高精度的同时，实现了高效的整数域计算，非常适合硬件加速和嵌入式部署。
