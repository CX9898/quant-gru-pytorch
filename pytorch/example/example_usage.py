"""
QuantGRU é‡åŒ–åº“ä½¿ç”¨ç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ QuantGRU è¿›è¡Œï¼š
- åŸºæœ¬æ¨ç†ï¼ˆæµ®ç‚¹/é‡åŒ–ï¼‰
- é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰
- æ ¡å‡†æ–¹æ³•é€‰æ‹©ï¼ˆMinMax / SQNR / Percentileï¼‰
- åŒå‘ GRU
- ONNX å¯¼å‡ºï¼ˆfloat æµ®ç‚¹ / qdq ä¼ªé‡åŒ–ï¼‰
- é‡åŒ–å‚æ•°å¯¼å‡º/å¯¼å…¥
- é‡åŒ–é…ç½®è°ƒæ•´ä¸æŸ¥çœ‹
"""

import torch
import torch.nn as nn

# æ·»åŠ åº“è·¯å¾„ï¼ˆæ ¹æ®å®é™…å®‰è£…ä½ç½®ä¿®æ”¹ï¼‰
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from quant_gru import QuantGRU, print_quant_config, print_quant_params


def example_basic_usage():
    """
    ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨ï¼ˆéé‡åŒ–ï¼‰
    
    ä¸ nn.GRU ç”¨æ³•å®Œå…¨ä¸€è‡´
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1: åŸºæœ¬ä½¿ç”¨ï¼ˆéé‡åŒ–ï¼‰")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºæ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True  # è¾“å…¥æ ¼å¼ [batch, seq, feature]
    ).cuda()
    
    # åˆ›å»ºè¾“å…¥æ•°æ®
    x = torch.randn(batch_size, seq_len, input_size).cuda()
    
    # å‰å‘ä¼ æ’­
    output, h_n = gru(x)
    
    print(f"è¾“å…¥å½¢çŠ¶:   {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶:   {output.shape}")
    print(f"éšè—çŠ¶æ€:   {h_n.shape}")
    print("âœ… åŸºæœ¬ä½¿ç”¨å®Œæˆï¼")


def example_quantization_with_json():
    """
    ç¤ºä¾‹ 2: ä½¿ç”¨ JSON é…ç½®è¿›è¡Œé‡åŒ–
    
    æ¨èæ–¹å¼ï¼šé€šè¿‡ JSON æ–‡ä»¶é…ç½®é‡åŒ–å‚æ•°
    
    æ³¨æ„ï¼šåœ¨ JSON é…ç½®æ–‡ä»¶ä¸­ï¼Œå¯ä»¥ä¸ºæƒé‡(W, R)å’Œåç½®(bw, br)è®¾ç½®é‡åŒ–ç²’åº¦ï¼š
    - "quantization_granularity": "PER_TENSOR" - æ•´ä¸ªtensorä¸€ä¸ªscale
    - "quantization_granularity": "PER_GATE" - æ¯ä¸ªé—¨ä¸€ä¸ªscaleï¼ˆ3ä¸ªé—¨ï¼‰
    - "quantization_granularity": "PER_CHANNEL" - æ¯ä¸ªè¾“å‡ºé€šé“ä¸€ä¸ªscaleï¼ˆé»˜è®¤ï¼‰
    
    è¯¦è§ç¤ºä¾‹ 13 äº†è§£å¦‚ä½•é€šè¿‡ä»£ç è®¾ç½®é‡åŒ–ç²’åº¦
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 2: ä½¿ç”¨ JSON é…ç½®è¿›è¡Œé‡åŒ–")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # 1. åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½é…ç½®
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # åŠ è½½ JSON é…ç½®ï¼ˆè‡ªåŠ¨è®¾ç½® use_quantizationï¼‰
    config_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        "config/gru_quant_bitwidth_config.json"
    )
    gru.load_bitwidth_config(config_path)
    print(f"âœ… åŠ è½½é…ç½®: {config_path}")
    print(f"   é‡åŒ–å¼€å…³: use_quantization = {gru.use_quantization}")
    
    # 2. æ ¡å‡†ï¼ˆä½¿ç”¨ä»£è¡¨æ€§æ•°æ®ï¼‰
    print("\nğŸ“Š å¼€å§‹æ ¡å‡†...")
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    
    # æ–°çš„æ ¡å‡†æ–¹å¼ï¼šè®¾ç½® calibrating=True åè¿›è¡Œ forward
    gru.calibrating = True
    _ = gru(calibration_data)
    gru.calibrating = False
    
    print("âœ… æ ¡å‡†å®Œæˆï¼")
    
    # 3. æ¨ç†
    print("\nğŸš€ å¼€å§‹æ¨ç†...")
    gru.use_quantization = True
    x = torch.randn(batch_size, seq_len, input_size).cuda()
    output, h_n = gru(x)
    
    print(f"è¾“å…¥å½¢çŠ¶:   {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶:   {output.shape}")
    print(f"éšè—çŠ¶æ€:   {h_n.shape}")
    print("âœ… é‡åŒ–æ¨ç†å®Œæˆï¼")


def example_quantization_manual(bitwidth=8):
    """
    ç¤ºä¾‹ 3: æ‰‹åŠ¨é…ç½®é‡åŒ–å‚æ•°
    
    ä¸ä½¿ç”¨ JSON æ–‡ä»¶ï¼Œç›´æ¥åœ¨ä»£ç ä¸­è®¾ç½®
    
    Args:
        bitwidth: é‡åŒ–ä½å®½ï¼ˆ8 æˆ– 16ï¼‰
    """
    print("\n" + "=" * 60)
    print(f"ç¤ºä¾‹ 3: æ‰‹åŠ¨é…ç½®é‡åŒ–å‚æ•° ({bitwidth}bit)")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # 1. åˆ›å»ºæ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # 2. è®¾ç½®ä½å®½
    gru.set_all_bitwidth(bitwidth)
    print(f"âœ… è®¾ç½®ä½å®½: {bitwidth}bit å¯¹ç§°é‡åŒ–")
    
    # 3. æ ¡å‡†
    print("\nğŸ“Š å¼€å§‹æ ¡å‡†...")
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    
    gru.calibrating = True
    _ = gru(calibration_data)
    gru.calibrating = False
    
    print("âœ… æ ¡å‡†å®Œæˆï¼")
    
    # 4. å¼€å¯é‡åŒ–å¹¶æ¨ç†
    gru.use_quantization = True
    print(f"   é‡åŒ–å¼€å…³: use_quantization = {gru.use_quantization}")
    
    print("\nğŸš€ å¼€å§‹æ¨ç†...")
    x = torch.randn(batch_size, seq_len, input_size).cuda()
    output, h_n = gru(x)
    
    print(f"è¾“å…¥å½¢çŠ¶:   {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶:   {output.shape}")
    print(f"éšè—çŠ¶æ€:   {h_n.shape}")
    print(f"âœ… {bitwidth}bit é‡åŒ–æ¨ç†å®Œæˆï¼")


def example_compare_precision(bitwidth=8):
    """
    ç¤ºä¾‹ 4: æ¯”è¾ƒé‡åŒ–å‰åçš„ç²¾åº¦å·®å¼‚
    
    Args:
        bitwidth: é‡åŒ–ä½å®½ï¼ˆ8 æˆ– 16ï¼‰
    """
    print("\n" + "=" * 60)
    print(f"ç¤ºä¾‹ 4: æ¯”è¾ƒé‡åŒ–å‰åçš„ç²¾åº¦å·®å¼‚ ({bitwidth}bit)")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºéé‡åŒ–æ¨¡å‹ï¼ˆåŸºå‡†ï¼‰
    gru_float = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True,
        use_quantization=False
    ).cuda()
    
    # åˆ›å»ºé‡åŒ–æ¨¡å‹ï¼ˆå¤åˆ¶æƒé‡ï¼‰
    quant_gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # å¤åˆ¶æƒé‡
    quant_gru.weight_ih_l0.data.copy_(gru_float.weight_ih_l0.data)
    quant_gru.weight_hh_l0.data.copy_(gru_float.weight_hh_l0.data)
    quant_gru.bias_ih_l0.data.copy_(gru_float.bias_ih_l0.data)
    quant_gru.bias_hh_l0.data.copy_(gru_float.bias_hh_l0.data)
    
    # æ ¡å‡†å¹¶å¼€å¯é‡åŒ–
    x = torch.randn(batch_size, seq_len, input_size).cuda()
    quant_gru.set_all_bitwidth(bitwidth)
    
    quant_gru.calibrating = True
    _ = quant_gru(x)
    quant_gru.calibrating = False
    
    quant_gru.use_quantization = True
    
    # æ¯”è¾ƒè¾“å‡º
    gru_float.eval()
    quant_gru.eval()
    
    with torch.no_grad():
        output_float, _ = gru_float(x)
        output_quant, _ = quant_gru(x)
    
    # è®¡ç®—è¯¯å·®
    mse = torch.mean((output_float - output_quant) ** 2).item()
    cos_sim = torch.nn.functional.cosine_similarity(
        output_float.flatten().unsqueeze(0),
        output_quant.flatten().unsqueeze(0)
    ).item()
    
    print(f"ğŸ“Š {bitwidth}bit ç²¾åº¦æ¯”è¾ƒç»“æœ:")
    print(f"   MSE (å‡æ–¹è¯¯å·®):     {mse:.6f}")
    print(f"   ä½™å¼¦ç›¸ä¼¼åº¦:         {cos_sim:.6f}")
    print(f"âœ… {bitwidth}bit ç²¾åº¦æ¯”è¾ƒå®Œæˆï¼")


def example_training(bitwidth=8):
    """
    ç¤ºä¾‹ 5: é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰
    
    ä»»åŠ¡ï¼šå­¦ä¹ è¾“å…¥åºåˆ—çš„ç®€å•å˜æ¢ï¼ˆè¾“å…¥ä¹˜ä»¥å›ºå®šç³»æ•°ï¼‰
    æ³¨æ„ï¼šå‰å‘ä¼ æ’­ä½¿ç”¨é‡åŒ–ï¼Œåå‘ä¼ æ’­ä½¿ç”¨æµ®ç‚¹
    
    Args:
        bitwidth: é‡åŒ–ä½å®½ï¼ˆ8 æˆ– 16ï¼‰
    """
    print("\n" + "=" * 60)
    print(f"ç¤ºä¾‹ 5: é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ ({bitwidth}bit)")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 64  # ä¸ input_size ç›¸åŒï¼Œä¾¿äºæ„é€ ç›®æ ‡
    batch_size = 8
    seq_len = 20
    num_epochs = 5
    
    # åˆ›å»ºæ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # å›ºå®šéšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œç»“æœä¸€è‡´
    torch.manual_seed(42)
    
    # ç”Ÿæˆå›ºå®šçš„è®­ç»ƒæ•°æ®ï¼ˆå­¦ä¹ è¾“å…¥çš„ 0.5 å€å˜æ¢ï¼‰
    x_train = torch.randn(batch_size, seq_len, input_size).cuda() * 0.5
    target_train = x_train * 0.5  # ç®€å•çš„çº¿æ€§å˜æ¢ä½œä¸ºç›®æ ‡
    
    # æ ¡å‡†
    gru.set_all_bitwidth(bitwidth)
    
    gru.calibrating = True
    _ = gru(x_train)
    gru.calibrating = False
    
    gru.use_quantization = True
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(gru.parameters(), lr=0.01)
    
    # è®­ç»ƒå¾ªç¯
    gru.train()
    print(f"\nğŸ‹ï¸ å¼€å§‹ {bitwidth}bit é‡åŒ–è®­ç»ƒ...")
    
    for epoch in range(num_epochs):
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        output, _ = gru(x_train)
        
        # è®¡ç®—æŸå¤±
        loss = torch.mean((output - target_train) ** 2)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        print(f"   Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.6f}")
    
    print(f"âœ… {bitwidth}bit è®­ç»ƒå®Œæˆï¼ï¼ˆLoss åº”æŒç»­ä¸‹é™ï¼‰")


def example_calibration_method():
    """
    ç¤ºä¾‹ 6: æ ¡å‡†æ–¹æ³•é€‰æ‹©
    
    QuantGRU æ”¯æŒä¸‰ç§æ ¡å‡†æ–¹æ³•:
    - 'minmax': å¿«é€Ÿï¼Œä½¿ç”¨ min/max èŒƒå›´
    - 'sqnr': SQNR ä¼˜åŒ–æœç´¢æœ€ä¼˜ scaleï¼ˆåŸºäºç›´æ–¹å›¾ï¼Œé«˜ç²¾åº¦ï¼‰
    - 'percentile': ç™¾åˆ†ä½è£å‰ªï¼ˆåŸºäºç›´æ–¹å›¾ï¼‰
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 6: æ ¡å‡†æ–¹æ³•é€‰æ‹©")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºåŸºå‡†æ¨¡å‹ï¼ˆFP32ï¼‰
    gru_base = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True,
        use_quantization=False
    ).cuda()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    torch.manual_seed(42)
    test_input = torch.randn(batch_size, seq_len, input_size).cuda()
    
    # FP32 åŸºå‡†è¾“å‡º
    gru_base.eval()
    with torch.no_grad():
        fp32_output, _ = gru_base(test_input)
    
    print("\nğŸ“Š å¯¹æ¯”ä¸‰ç§æ ¡å‡†æ–¹æ³•:")
    print("-" * 50)
    
    results = {}
    
    for method in ['minmax', 'sqnr', 'percentile']:
        # åˆ›å»ºé‡åŒ–æ¨¡å‹ï¼ˆå¤åˆ¶æƒé‡ï¼‰
        quant_gru = QuantGRU(
            input_size=input_size,
            hidden_size=hidden_size,
            batch_first=True
        ).cuda()
        
        # å¤åˆ¶æƒé‡
        quant_gru.weight_ih_l0.data.copy_(gru_base.weight_ih_l0.data)
        quant_gru.weight_hh_l0.data.copy_(gru_base.weight_hh_l0.data)
        quant_gru.bias_ih_l0.data.copy_(gru_base.bias_ih_l0.data)
        quant_gru.bias_hh_l0.data.copy_(gru_base.bias_hh_l0.data)
        
        # è®¾ç½®æ ¡å‡†æ–¹æ³•
        quant_gru.calibration_method = method
        
        # å¦‚æœæ˜¯ percentile æ–¹æ³•ï¼Œå¯ä»¥è®¾ç½®ç™¾åˆ†ä½å€¼
        if method == 'percentile':
            quant_gru.percentile_value = 99.99
        
        # è®¾ç½®ä½å®½
        quant_gru.set_all_bitwidth(16)
        
        # å¤šæ‰¹æ¬¡æ ¡å‡†ï¼ˆsqnr/percentile æ–¹æ³•åœ¨å¤šæ‰¹æ¬¡ä¸‹æ•ˆæœæ›´å¥½ï¼‰
        quant_gru.calibrating = True
        for _ in range(3):
            calib_data = torch.randn(batch_size, seq_len, input_size).cuda()
            _ = quant_gru(calib_data)
        quant_gru.calibrating = False
        
        # å¼€å¯é‡åŒ–å¹¶æ¨ç†
        quant_gru.use_quantization = True
        quant_gru.eval()
        
        with torch.no_grad():
            quant_output, _ = quant_gru(test_input)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        cos_sim = torch.nn.functional.cosine_similarity(
            fp32_output.flatten().unsqueeze(0),
            quant_output.flatten().unsqueeze(0)
        ).item()
        
        results[method] = cos_sim
        method_desc = {
            'minmax': 'MinMax (å¿«é€Ÿ)',
            'sqnr': 'SQNR (é«˜ç²¾åº¦)',
            'percentile': 'Percentile (æŠ—å¼‚å¸¸å€¼)'
        }[method]
        print(f"   {method_desc:<25} ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.6f}")
    
    print("-" * 50)
    print("\nğŸ’¡ é€‰æ‹©å»ºè®®:")
    print("   â€¢ minmax:     æ ¡å‡†é€Ÿåº¦å¿«ï¼Œé€‚åˆå¿«é€Ÿè¿­ä»£å’Œè°ƒè¯•")
    print("   â€¢ sqnr:       ç²¾åº¦æ›´é«˜ï¼Œæœç´¢æœ€ä¼˜ scaleï¼ˆæ¨èï¼‰")
    print("   â€¢ percentile: å¯¹å¼‚å¸¸å€¼é²æ£’ï¼Œé€‚åˆå«å™ªå£°æ•°æ®")
    print(f"\n   é»˜è®¤ä½¿ç”¨ 'minmax' æ–¹æ³•")
    print("âœ… æ ¡å‡†æ–¹æ³•å¯¹æ¯”å®Œæˆï¼")


def example_bidirectional():
    """
    ç¤ºä¾‹ 7: åŒå‘ GRU
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 7: åŒå‘ GRU")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºåŒå‘æ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True,
        bidirectional=True  # åŒå‘
    ).cuda()
    
    # æ ¡å‡†å¹¶å¼€å¯é‡åŒ–
    x = torch.randn(batch_size, seq_len, input_size).cuda()
    gru.set_all_bitwidth(8)
    
    gru.calibrating = True
    _ = gru(x)
    gru.calibrating = False
    
    gru.use_quantization = True
    
    # æ¨ç†
    output, h_n = gru(x)
    
    print(f"è¾“å…¥å½¢çŠ¶:   {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶:   {output.shape}  (hidden_size * 2 = {hidden_size * 2})")
    print(f"éšè—çŠ¶æ€:   {h_n.shape}  (num_directions = 2)")
    print("âœ… åŒå‘ GRU å®Œæˆï¼")


def example_onnx_export():
    """
    ç¤ºä¾‹ 8: ONNX å¯¼å‡º
    
    QuantGRU æ”¯æŒå¯¼å‡ºä¸º ONNX æ ¼å¼ï¼Œä¾¿äºéƒ¨ç½²åˆ°å„ç±»æ¨ç†å¼•æ“ã€‚
    
    å¯¼å‡ºæ¨¡å¼ (export_mode):
    - False (é»˜è®¤): ä½¿ç”¨ CUDA C++ å®ç°ï¼ˆé«˜æ€§èƒ½æ¨ç†ï¼‰
    - True: ä½¿ç”¨çº¯ PyTorch å®ç°ï¼ˆå¯è¢« ONNX è¿½è¸ªï¼‰
    
    å¯¼å‡ºæ ¼å¼ (export_format):
    - 'float': æµ®ç‚¹æ ¼å¼ï¼ˆé»˜è®¤ï¼‰
    - 'qdq': QDQ ä¼ªé‡åŒ–æ ¼å¼ï¼ˆé‡åŒ–æ¨¡å‹æ¨èï¼Œéœ€å…ˆæ ¡å‡†ï¼‰
    
    æ³¨æ„äº‹é¡¹:
    - å¯¼å‡ºå‰å¿…é¡»è®¾ç½® export_mode = True
    - QDQ æ ¼å¼éœ€è¦å…ˆæ ¡å‡†
    - å¯¼å‡ºååº”æ¢å¤ export_mode = False ä»¥ä½¿ç”¨ CUDA æ¨ç†
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 8: ONNX å¯¼å‡º")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 1
    seq_len = 20
    
    # 1. åˆ›å»ºå¹¶é…ç½®æ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    print("\nğŸ“¦ æ­¥éª¤ 1: é…ç½®é‡åŒ–å‚æ•°")
    gru.set_all_bitwidth(16)  # 16bit é‡åŒ–
    print("   âœ… è®¾ç½® 16bit é‡åŒ–")
    
    # 2. æ ¡å‡†
    print("\nğŸ“Š æ­¥éª¤ 2: æ ¡å‡†æ¨¡å‹")
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    
    gru.calibrating = True
    _ = gru(calibration_data)
    gru.calibrating = False
    gru.finalize_calibration()
    
    gru.use_quantization = True
    print("   âœ… æ ¡å‡†å®Œæˆ")
    
    # 3. åˆ‡æ¢åˆ°å¯¼å‡ºæ¨¡å¼
    print("\nğŸ”„ æ­¥éª¤ 3: åˆ‡æ¢åˆ°å¯¼å‡ºæ¨¡å¼")
    gru.export_mode = True
    gru.eval()
    print(f"   export_mode = {gru.export_mode}")
    print(f"   å¯¼å‡ºæ ¼å¼: {gru.export_format}")
    
    # 4. å¯¼å‡º ONNX
    print("\nğŸ“¤ æ­¥éª¤ 4: å¯¼å‡º ONNX æ¨¡å‹")
    dummy_input = torch.randn(batch_size, seq_len, input_size).cuda()
    onnx_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        "quant_gru_example.onnx"
    )
    
    torch.onnx.export(
        gru,
        dummy_input,
        onnx_path,
        input_names=['input'],
        output_names=['output', 'hidden'],
        dynamic_axes={
            'input': {0: 'batch', 1: 'seq_len'},
            'output': {0: 'batch', 1: 'seq_len'}
        },
        opset_version=14,
        dynamo=False,  # ä½¿ç”¨ä¼ ç»Ÿ TorchScript å¯¼å‡ºï¼Œé¿å… torch.export å…¼å®¹æ€§é—®é¢˜
        verbose=False
    )
    print(f"   âœ… å¯¼å‡ºæˆåŠŸ: {onnx_path}")
    
    # 5. éªŒè¯å¯¼å‡ºçš„æ¨¡å‹
    print("\nğŸ” æ­¥éª¤ 5: éªŒè¯ ONNX æ¨¡å‹")
    try:
        import onnx
        model = onnx.load(onnx_path)
        onnx.checker.check_model(model)
        print("   âœ… ONNX æ¨¡å‹éªŒè¯é€šè¿‡")
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        print(f"\n   æ¨¡å‹ä¿¡æ¯:")
        print(f"   - IR ç‰ˆæœ¬: {model.ir_version}")
        print(f"   - Opset ç‰ˆæœ¬: {model.opset_import[0].version}")
        print(f"   - è¾“å…¥æ•°é‡: {len(model.graph.input)}")
        print(f"   - è¾“å‡ºæ•°é‡: {len(model.graph.output)}")
    except ImportError:
        print("   âš ï¸ æœªå®‰è£… onnx åº“ï¼Œè·³è¿‡éªŒè¯")
    except Exception as e:
        print(f"   âš ï¸ éªŒè¯å¤±è´¥: {e}")
    
    # 6. æ¢å¤ CUDA æ¨¡å¼
    gru.export_mode = False
    print(f"\nğŸ”„ æ¢å¤ CUDA æ¨¡å¼: export_mode = {gru.export_mode}")
    
    print("\nâœ… ONNX å¯¼å‡ºç¤ºä¾‹å®Œæˆï¼")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists(onnx_path):
        os.remove(onnx_path)
        print(f"   å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {onnx_path}")


def example_onnx_export_modes():
    """
    ç¤ºä¾‹ 9: ONNX å¯¼å‡ºæ ¼å¼å¯¹æ¯”
    
    æ¼”ç¤ºä¸¤ç§ ONNX å¯¼å‡ºæ ¼å¼çš„åŒºåˆ«å’Œä½¿ç”¨åœºæ™¯:
    - 'float': æµ®ç‚¹æ ¼å¼ï¼ˆé»˜è®¤ï¼‰
    - 'qdq': QDQ ä¼ªé‡åŒ–æ ¼å¼ï¼ˆé‡åŒ–æ¨¡å‹æ¨èï¼Œéœ€å…ˆæ ¡å‡†ï¼‰
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 9: ONNX å¯¼å‡ºæ ¼å¼å¯¹æ¯”")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 4
    seq_len = 20
    
    # åˆ›å»ºåŸºå‡†æ¨¡å‹
    gru_base = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # æ ¡å‡†
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    gru_base.set_all_bitwidth(16)
    
    gru_base.calibrating = True
    _ = gru_base(calibration_data)
    gru_base.calibrating = False
    gru_base.finalize_calibration()
    
    gru_base.use_quantization = True
    
    # è·å– CUDA å‚è€ƒè¾“å‡º
    gru_base.eval()
    test_input = torch.randn(batch_size, seq_len, input_size).cuda()
    with torch.no_grad():
        cuda_output, _ = gru_base(test_input)
    
    print("\nğŸ“Š å¯¹æ¯”ä¸¤ç§ ONNX å¯¼å‡ºæ ¼å¼:")
    print("-" * 50)
    
    modes = [
        ('float', 'æµ®ç‚¹æ ¼å¼ï¼ˆé»˜è®¤ï¼‰'),
        ('qdq', 'QDQ ä¼ªé‡åŒ–æ ¼å¼ï¼ˆé‡åŒ–æ¨èï¼Œéœ€å…ˆæ ¡å‡†ï¼‰')
    ]
    
    gru_base.export_mode = True
    
    for mode, desc in modes:
        gru_base.export_format = mode
        
        with torch.no_grad():
            export_output, _ = gru_base(test_input)
        
        # è®¡ç®—ä¸ CUDA è¾“å‡ºçš„ç›¸ä¼¼åº¦
        cos_sim = torch.nn.functional.cosine_similarity(
            cuda_output.flatten().unsqueeze(0),
            export_output.flatten().unsqueeze(0)
        ).item()
        
        mse = torch.mean((cuda_output - export_output) ** 2).item()
        
        print(f"\n   æ¨¡å¼: {mode}")
        print(f"   æè¿°: {desc}")
        print(f"   ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.6f}")
        print(f"   MSE: {mse:.8f}")
    
    gru_base.export_mode = False
    
    print("\n" + "-" * 50)
    print("\nğŸ’¡ å¯¼å‡ºæ ¼å¼é€‰æ‹©å»ºè®®:")
    print("   â€¢ 'float': éé‡åŒ–æ¨¡å‹ã€é€šç”¨éƒ¨ç½²ï¼ˆé»˜è®¤ï¼‰")
    print("   â€¢ 'qdq':   é‡åŒ–æ¨¡å‹éƒ¨ç½²ï¼Œæ¨ç†å¼•æ“è‡ªåŠ¨ä¼˜åŒ–ï¼ˆéœ€å…ˆæ ¡å‡†ï¼‰")
    
    print("\nâœ… å¯¼å‡ºæ ¼å¼å¯¹æ¯”å®Œæˆï¼")


def example_quant_params_export_import():
    """
    ç¤ºä¾‹ 10: é‡åŒ–å‚æ•°å¯¼å‡º/å¯¼å…¥
    
    æ¼”ç¤ºå¦‚ä½•ï¼š
    1. æ ¡å‡†åå¯¼å‡ºé‡åŒ–å‚æ•°åˆ° JSON æ–‡ä»¶
    2. åœ¨éƒ¨ç½²ç¯å¢ƒä» JSON åŠ è½½é‡åŒ–å‚æ•°ï¼ˆæ— éœ€é‡æ–°æ ¡å‡†ï¼‰
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 10: é‡åŒ–å‚æ•°å¯¼å‡º/å¯¼å…¥")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # ========== è®­ç»ƒ/æ ¡å‡†ç¯å¢ƒ ==========
    print("\nğŸ“¦ [è®­ç»ƒç¯å¢ƒ] æ ¡å‡†å¹¶å¯¼å‡ºé‡åŒ–å‚æ•°")
    print("-" * 50)
    
    gru_train = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    # è®¾ç½®ä½å®½å¹¶æ ¡å‡†
    gru_train.set_all_bitwidth(8)
    gru_train.calibration_method = 'sqnr'  # ä½¿ç”¨ SQNR é«˜ç²¾åº¦æ ¡å‡†
    
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    gru_train.calibrating = True
    _ = gru_train(calibration_data)
    gru_train.calibrating = False
    gru_train.finalize_calibration()
    
    print("   âœ… æ ¡å‡†å®Œæˆ")
    
    # å¯¼å‡ºé‡åŒ–å‚æ•°
    quant_params_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        "example_quant_params.json"
    )
    gru_train.export_quant_params(quant_params_path, verbose=True)
    
    # åŒæ—¶ä¿å­˜æ¨¡å‹æƒé‡
    weights_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
        "example_weights.pth"
    )
    torch.save(gru_train.state_dict(), weights_path)
    print(f"   âœ… æƒé‡å·²ä¿å­˜åˆ°: {weights_path}")
    
    # ========== éƒ¨ç½²ç¯å¢ƒ ==========
    print("\nğŸ“¥ [éƒ¨ç½²ç¯å¢ƒ] åŠ è½½é‡åŒ–å‚æ•°")
    print("-" * 50)
    
    # ä» JSON è¯»å–æ¨¡å‹é…ç½®
    import json
    with open(quant_params_path) as f:
        config = json.load(f)["model_info"]
    
    # åˆ›å»ºæ¨¡å‹
    gru_deploy = QuantGRU(
        input_size=config["input_size"],
        hidden_size=config["hidden_size"],
        batch_first=config["batch_first"],
        bidirectional=config["bidirectional"]
    ).cuda()
    
    # åŠ è½½æƒé‡
    gru_deploy.load_state_dict(torch.load(weights_path))
    print(f"   âœ… æƒé‡å·²åŠ è½½")
    
    # åŠ è½½é‡åŒ–å‚æ•°
    gru_deploy.load_quant_params(quant_params_path, verbose=True)
    
    # å¼€å¯é‡åŒ–æ¨ç†
    gru_deploy.use_quantization = True
    
    # ========== éªŒè¯ä¸€è‡´æ€§ ==========
    print("\nğŸ” éªŒè¯å¯¼å‡º/å¯¼å…¥ä¸€è‡´æ€§")
    print("-" * 50)
    
    gru_train.use_quantization = True
    gru_train.eval()
    gru_deploy.eval()
    
    test_input = torch.randn(batch_size, seq_len, input_size).cuda()
    with torch.no_grad():
        output_train, _ = gru_train(test_input)
        output_deploy, _ = gru_deploy(test_input)
    
    mse = torch.mean((output_train - output_deploy) ** 2).item()
    cos_sim = torch.nn.functional.cosine_similarity(
        output_train.flatten().unsqueeze(0),
        output_deploy.flatten().unsqueeze(0)
    ).item()
    
    print(f"   è®­ç»ƒæ¨¡å‹ vs éƒ¨ç½²æ¨¡å‹:")
    print(f"   MSE: {mse:.10f}")
    print(f"   ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.6f}")
    
    if mse < 1e-10:
        print("   âœ… å¯¼å‡º/å¯¼å…¥ä¸€è‡´æ€§éªŒè¯é€šè¿‡ï¼")
    else:
        print("   âš ï¸ å­˜åœ¨å¾®å°å·®å¼‚ï¼ˆå¯èƒ½æ˜¯æ•°å€¼ç²¾åº¦é—®é¢˜ï¼‰")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    for path in [quant_params_path, weights_path]:
        if os.path.exists(path):
            os.remove(path)
    print(f"\n   å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
    
    print("\nâœ… é‡åŒ–å‚æ•°å¯¼å‡º/å¯¼å…¥ç¤ºä¾‹å®Œæˆï¼")


def example_adjust_quant_config():
    """
    ç¤ºä¾‹ 11: è°ƒæ•´é‡åŒ–é…ç½®
    
    æ¼”ç¤ºå¦‚ä½•ï¼š
    1. æŸ¥çœ‹å½“å‰é‡åŒ–é…ç½®
    2. è°ƒæ•´å•ä¸ªç®—å­çš„ä½å®½/scale
    3. è§‚å¯Ÿè°ƒæ•´å‰åçš„æ•ˆæœ
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 11: è°ƒæ•´é‡åŒ–é…ç½®")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºå¹¶æ ¡å‡†æ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    gru.set_all_bitwidth(8)
    
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    gru.calibrating = True
    _ = gru(calibration_data)
    gru.calibrating = False
    gru.finalize_calibration()
    
    print("\nğŸ“‹ æŸ¥çœ‹é‡åŒ–é…ç½®")
    print("-" * 50)
    
    # æŸ¥çœ‹å•ä¸ªç®—å­é…ç½®
    config = gru.get_quant_config("update_gate_output")
    print(f"   update_gate_output é…ç½®: {config}")
    
    # æŸ¥çœ‹æ‰€æœ‰é…ç½®ï¼ˆä½¿ç”¨è°ƒè¯•å·¥å…·ï¼‰
    print("\nğŸ“Š æ‰€æœ‰é‡åŒ–é…ç½®:")
    print_quant_config(gru, ["x", "h", "update_gate_output", "reset_gate_output", "new_gate_output"])
    
    # ========== è°ƒæ•´é…ç½® ==========
    print("\nğŸ”§ è°ƒæ•´ update_gate_output ä½å®½: 8bit -> 16bit")
    print("-" * 50)
    
    # è°ƒæ•´å‰è·å–åŸºå‡†è¾“å‡º
    gru.use_quantization = True
    gru.eval()
    test_input = torch.randn(batch_size, seq_len, input_size).cuda()
    
    with torch.no_grad():
        output_before, _ = gru(test_input)
    
    # è°ƒæ•´ä½å®½ï¼ˆä¼šè‡ªåŠ¨è°ƒæ•´ scaleï¼‰
    gru.adjust_quant_config("update_gate_output", bitwidth=16, verbose=True)
    
    # è°ƒæ•´åè¾“å‡º
    with torch.no_grad():
        output_after, _ = gru(test_input)
    
    # æ¯”è¾ƒå·®å¼‚
    diff = torch.mean((output_before - output_after) ** 2).item()
    print(f"\n   è°ƒæ•´å‰åè¾“å‡ºå·®å¼‚ (MSE): {diff:.8f}")
    
    # æŸ¥çœ‹è°ƒæ•´åçš„é…ç½®
    new_config = gru.get_quant_config("update_gate_output")
    print(f"   è°ƒæ•´å update_gate_output é…ç½®: {new_config}")
    
    print("\nâœ… é‡åŒ–é…ç½®è°ƒæ•´ç¤ºä¾‹å®Œæˆï¼")


def example_debug_tools():
    """
    ç¤ºä¾‹ 12: è°ƒè¯•å·¥å…·ä½¿ç”¨
    
    æ¼”ç¤ºè°ƒè¯•å·¥å…·çš„ä½¿ç”¨æ–¹æ³•ï¼š
    - print_quant_params(): æ‰“å°é‡åŒ–å‚æ•°
    - print_quant_config(): æ‰“å°é‡åŒ–é…ç½®
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 12: è°ƒè¯•å·¥å…·ä½¿ç”¨")
    print("=" * 60)
    
    from quant_gru import print_quant_params, print_quant_config, print_quant_ranges
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºå¹¶æ ¡å‡†æ¨¡å‹
    gru = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True
    ).cuda()
    
    gru.set_all_bitwidth(8)
    gru.calibration_method = 'minmax'  # minmax æ–¹æ³•ä¼šè®°å½•èŒƒå›´
    
    calibration_data = torch.randn(batch_size, seq_len, input_size).cuda()
    gru.calibrating = True
    _ = gru(calibration_data)
    gru.calibrating = False
    
    # 1. æ‰“å°é‡åŒ–èŒƒå›´ï¼ˆæ ¡å‡†æ”¶é›†çš„æ•°å€¼èŒƒå›´ï¼‰
    print("\nğŸ“Š 1. é‡åŒ–èŒƒå›´ (print_quant_ranges)")
    print("-" * 50)
    print_quant_ranges(gru)
    
    # 2. å®Œæˆæ ¡å‡†
    gru.finalize_calibration()
    
    # 3. æ‰“å°é‡åŒ–å‚æ•°
    print("\nğŸ“Š 2. é‡åŒ–å‚æ•° (print_quant_params)")
    print("-" * 50)
    print_quant_params(gru)
    
    # 4. æ‰“å°é‡åŒ–é…ç½®ï¼ˆæ›´è¯¦ç»†çš„è§†å›¾ï¼‰
    print("\nğŸ“Š 3. é‡åŒ–é…ç½®è¯¦æƒ… (print_quant_config)")
    print("-" * 50)
    print_quant_config(gru)
    
    print("\nâœ… è°ƒè¯•å·¥å…·ç¤ºä¾‹å®Œæˆï¼")


def example_weight_bias_granularity():
    """
    ç¤ºä¾‹ 13: æƒé‡å’Œåç½®çš„é‡åŒ–ç²’åº¦è®¾ç½®
    
    æ¼”ç¤ºå¦‚ä½•ä¸ºæƒé‡(W, R)å’Œåç½®(bw, br)è®¾ç½®ä¸åŒçš„é‡åŒ–ç²’åº¦ï¼š
    - PER_TENSOR: æ•´ä¸ªtensorä½¿ç”¨ä¸€ä¸ªscaleï¼ˆæœ€ç®€å•ï¼Œç²¾åº¦å¯èƒ½è¾ƒä½ï¼‰
    - PER_GATE: æ¯ä¸ªé—¨ä½¿ç”¨ä¸€ä¸ªscaleï¼ˆ3ä¸ªé—¨ï¼šupdate, reset, newï¼‰
    - PER_CHANNEL: æ¯ä¸ªè¾“å‡ºé€šé“ä½¿ç”¨ä¸€ä¸ªscaleï¼ˆé»˜è®¤ï¼Œç²¾åº¦æœ€é«˜ï¼‰
    
    æ³¨æ„ï¼šé‡åŒ–ç²’åº¦ä»…å¯¹ W, R, bw, br å››ä¸ªç®—å­æœ‰æ•ˆ
    """
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 13: æƒé‡å’Œåç½®çš„é‡åŒ–ç²’åº¦è®¾ç½®")
    print("=" * 60)
    
    # æ¨¡å‹å‚æ•°
    input_size = 64
    hidden_size = 128
    batch_size = 8
    seq_len = 20
    
    # åˆ›å»ºåŸºå‡†æ¨¡å‹ï¼ˆFP32ï¼‰
    gru_base = QuantGRU(
        input_size=input_size,
        hidden_size=hidden_size,
        batch_first=True,
        use_quantization=False
    ).cuda()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    torch.manual_seed(42)
    test_input = torch.randn(batch_size, seq_len, input_size).cuda()
    
    # FP32 åŸºå‡†è¾“å‡º
    gru_base.eval()
    with torch.no_grad():
        fp32_output, _ = gru_base(test_input)
    
    print("\nğŸ“Š å¯¹æ¯”ä¸‰ç§é‡åŒ–ç²’åº¦:")
    print("-" * 60)
    
    granularity_configs = [
        ('PER_TENSOR', 'æ•´ä¸ªtensorä¸€ä¸ªscaleï¼ˆæœ€ç®€å•ï¼‰'),
        ('PER_GATE', 'æ¯ä¸ªé—¨ä¸€ä¸ªscaleï¼ˆ3ä¸ªé—¨ï¼‰'),
        ('PER_CHANNEL', 'æ¯ä¸ªè¾“å‡ºé€šé“ä¸€ä¸ªscaleï¼ˆé»˜è®¤ï¼‰')
    ]
    
    results = {}
    
    for granularity_name, description in granularity_configs:
        print(f"\nğŸ”§ é…ç½®: {granularity_name}")
        print(f"   æè¿°: {description}")
        
        # åˆ›å»ºé‡åŒ–æ¨¡å‹ï¼ˆå¤åˆ¶æƒé‡ï¼‰
        quant_gru = QuantGRU(
            input_size=input_size,
            hidden_size=hidden_size,
            batch_first=True
        ).cuda()
        
        # å¤åˆ¶æƒé‡
        quant_gru.weight_ih_l0.data.copy_(gru_base.weight_ih_l0.data)
        quant_gru.weight_hh_l0.data.copy_(gru_base.weight_hh_l0.data)
        quant_gru.bias_ih_l0.data.copy_(gru_base.bias_ih_l0.data)
        quant_gru.bias_hh_l0.data.copy_(gru_base.bias_hh_l0.data)
        
        # è®¾ç½®ä½å®½
        quant_gru.set_all_bitwidth(8)
        
        # è®¾ç½®é‡åŒ–ç²’åº¦ï¼ˆä»…å¯¹ W, R, bw, br æœ‰æ•ˆï¼‰
        granularity_map = {
            'PER_TENSOR': 0,
            'PER_GATE': 1,
            'PER_CHANNEL': 2
        }
        granularity_value = granularity_map[granularity_name]
        
        # è®¾ç½®æƒé‡å’Œåç½®çš„é‡åŒ–ç²’åº¦
        quant_gru._bitwidth_config.W_granularity_ = granularity_value
        quant_gru._bitwidth_config.R_granularity_ = granularity_value
        quant_gru._bitwidth_config.bw_granularity_ = granularity_value
        quant_gru._bitwidth_config.br_granularity_ = granularity_value
        
        print(f"   âœ… W_granularity = {granularity_value} ({granularity_name})")
        print(f"   âœ… R_granularity = {granularity_value} ({granularity_name})")
        print(f"   âœ… bw_granularity = {granularity_value} ({granularity_name})")
        print(f"   âœ… br_granularity = {granularity_value} ({granularity_name})")
        
        # æ ¡å‡†
        quant_gru.calibration_method = 'minmax'
        quant_gru.calibrating = True
        _ = quant_gru(test_input)
        quant_gru.calibrating = False
        quant_gru.finalize_calibration()
        
        # å¼€å¯é‡åŒ–å¹¶æ¨ç†
        quant_gru.use_quantization = True
        quant_gru.eval()
        
        with torch.no_grad():
            quant_output, _ = quant_gru(test_input)
        
        # è®¡ç®—ç²¾åº¦æŒ‡æ ‡
        mse = torch.mean((fp32_output - quant_output) ** 2).item()
        cos_sim = torch.nn.functional.cosine_similarity(
            fp32_output.flatten().unsqueeze(0),
            quant_output.flatten().unsqueeze(0)
        ).item()
        
        results[granularity_name] = {
            'mse': mse,
            'cos_sim': cos_sim
        }
        
        print(f"   ğŸ“ˆ MSE: {mse:.8f}")
        print(f"   ğŸ“ˆ ä½™å¼¦ç›¸ä¼¼åº¦: {cos_sim:.6f}")
    
    print("\n" + "-" * 60)
    print("\nğŸ“Š é‡åŒ–ç²’åº¦å¯¹æ¯”æ€»ç»“:")
    print("-" * 60)
    for granularity_name, description in granularity_configs:
        result = results[granularity_name]
        print(f"   {granularity_name:<15} MSE: {result['mse']:.8f}, ä½™å¼¦ç›¸ä¼¼åº¦: {result['cos_sim']:.6f}")
    
    print("\nâœ… é‡åŒ–ç²’åº¦è®¾ç½®ç¤ºä¾‹å®Œæˆï¼")


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("=" * 60)
    print("  QuantGRU é‡åŒ–åº“ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯: éœ€è¦ CUDA æ”¯æŒ")
        return
    
    try:
        # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        example_basic_usage()
        example_quantization_with_json()
        
        # ç¤ºä¾‹ 3: æ‰‹åŠ¨é…ç½®é‡åŒ–å‚æ•°ï¼ˆ8bit å’Œ 16bitï¼‰
        example_quantization_manual(bitwidth=8)
        example_quantization_manual(bitwidth=16)
        
        # ç¤ºä¾‹ 4: æ¯”è¾ƒé‡åŒ–å‰åçš„ç²¾åº¦å·®å¼‚ï¼ˆ8bit å’Œ 16bitï¼‰
        example_compare_precision(bitwidth=8)
        example_compare_precision(bitwidth=16)
        
        # ç¤ºä¾‹ 5: é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆ8bit å’Œ 16bitï¼‰
        example_training(bitwidth=8)
        example_training(bitwidth=16)
        
        # ç¤ºä¾‹ 6: æ ¡å‡†æ–¹æ³•é€‰æ‹©
        example_calibration_method()
        
        # ç¤ºä¾‹ 7: åŒå‘ GRU
        example_bidirectional()
        
        # ç¤ºä¾‹ 8: ONNX å¯¼å‡º
        example_onnx_export()
        
        # ç¤ºä¾‹ 9: ONNX å¯¼å‡ºæ ¼å¼å¯¹æ¯”
        example_onnx_export_modes()
        
        # ç¤ºä¾‹ 10: é‡åŒ–å‚æ•°å¯¼å‡º/å¯¼å…¥
        example_quant_params_export_import()
        
        # ç¤ºä¾‹ 11: è°ƒæ•´é‡åŒ–é…ç½®
        example_adjust_quant_config()
        
        # ç¤ºä¾‹ 12: è°ƒè¯•å·¥å…·ä½¿ç”¨
        example_debug_tools()
        
        # ç¤ºä¾‹ 13: æƒé‡å’Œåç½®çš„é‡åŒ–ç²’åº¦è®¾ç½®
        example_weight_bias_granularity()
        
        print("\n" + "=" * 60)
        print("  æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
